{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac408b5e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a96d02d6346fa7399cf6da0111ce0937",
     "grade": false,
     "grade_id": "cell-b00828259c8e42e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# RO47019: Intelligent Control Systems Practical Assignment\n",
    "* Period: 2022-2023, Q3\n",
    "* Course homepage: https://brightspace.tudelft.nl/d2l/home/500969\n",
    "* Instructor: Cosimo Della Santina (C.DellaSantina@tudelft.nl)\n",
    "* Teaching assistant: Ruben Martin Rodriguez (R.MartinRodriguez@student.tudelft.nl)\n",
    "* (c) TU Delft, 2023\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or `YOUR ANSWER HERE`. Remove `raise NotImplementedError()` afterwards. Moreover, if you see an empty cell, please DO NOT delete it, instead run that cell as you would run all other cells. Please fill in your name(s) and other required details below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9e220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please fill in your names, student numbers, netID, and emails below.\n",
    "STUDENT_1_NAME = \"\"\n",
    "STUDENT_1_STUDENT_NUMBER = \"\"\n",
    "STUDENT_1_NETID = \"\"\n",
    "STUDENT_1_EMAIL = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba32571",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "042927213b84aa368aa3ea72caa4cb60",
     "grade": true,
     "grade_id": "cell-9f148ec62e0de49c",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Note: this block is a check that you have filled in the above information.\n",
    "# It will throw an AssertionError until all fields are filled\n",
    "assert STUDENT_1_NAME != \"\"\n",
    "assert STUDENT_1_STUDENT_NUMBER != \"\"\n",
    "assert STUDENT_1_NETID != \"\"\n",
    "assert STUDENT_1_EMAIL != \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af317a94",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e76ef40fcc3f08a0484661497162a1a9",
     "grade": false,
     "grade_id": "cell-4ea391677951116c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### General announcements\n",
    "\n",
    "* Do *not* share your solutions, and do *not* copy solutions from others. By submitting your solutions, you claim that you alone are responsible for this code.\n",
    "\n",
    "* Do *not* email questions directly, since we want to provide everybody with the same information and avoid repeating the same answers. Instead, please post your questions regarding this assignment in the correct support forum on Brightspace, this way everybody can benefit from the response. If you do have a particular question that you want to ask directly, please use the scheduled Q&A hours to ask the TA.\n",
    "\n",
    "* There is a strict deadline for each assignment. Students are responsible to ensure that they have uploaded their work in time. So, please double check that your upload succeeded to the Brightspace and avoid any late penalties.\n",
    "\n",
    "* This [Jupyter notebook](https://jupyter.org/) uses `nbgrader` to help us with automated tests. `nbgrader` will make various cells in this notebook \"uneditable\" or \"unremovable\" and gives them a special id in the cell metadata. This way, when we run our checks, the system will check the existence of the cell ids and verify the number of points and which checks must be run. While there are ways that you can edit the metadata and work around the restrictions to delete or modify these special cells, you should not do that since then our nbgrader backend will not be able to parse your notebook and give you points for the assignment. You are free to add additional cells, but if you find a cell that you cannot modify or remove, please know that this is on purpose.\n",
    "\n",
    "* This notebook will have in various places a line that throws a `NotImplementedError` exception. These are locations where the assignment requires you to adapt the code! These lines are just there as a reminder for youthat you have not yet adapted that particular piece of code, especially when you execute all the cells. Once your solution code replaced these lines, it should accordingly *not* throw any exceptions anymore.\n",
    "\n",
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c956945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "860bf3fb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3fc6fe2ac568810f7ae66b11d31ef6e0",
     "grade": false,
     "grade_id": "cell-60a0ce6bc7eb39ca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Problem 1 - Vision-based angle prediction (42.5p)\n",
    "\n",
    "**Authors:** Tom√°s Coleman (T.Coleman@tudelft.nl), Chuhan Zhang (C.Zhang-8@tudelft.nl)\n",
    "\n",
    "Run the following cells before starting the tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dae7e3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "498021754e66c656e7f420fd5992eff0",
     "grade": false,
     "grade_id": "cell-3817029f43b8b848",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Reloads the python files outside of this notebook automatically\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import all Python modules\n",
    "from distutils.util import strtobool\n",
    "from functools import partial\n",
    "from IPython.display import display, HTML  # For animations in the notebook\n",
    "from jax.config import config as jax_config\n",
    "\n",
    "jax_config.update(\"jax_platform_name\", \"cpu\")  # set default device to 'cpu'\n",
    "jax_config.update(\"jax_enable_x64\", True)  # double precision\n",
    "import jax\n",
    "from jax import jit, lax, random\n",
    "from jax import numpy as jnp\n",
    "import numpy as onp\n",
    "import cv2\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "from progressbar import progressbar\n",
    "from typing import Dict, Tuple\n",
    "from scipy import stats\n",
    "\n",
    "from jax_double_pendulum.robot_parameters import ROBOT_PARAMS\n",
    "from jax_double_pendulum.robot_simulation import simulate_robot\n",
    "from jax_double_pendulum.utils import normalize_link_angles\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from utils import *\n",
    "\n",
    "\n",
    "# define boolean to check if the notebook is run for the purposes of autograding\n",
    "AUTOGRADING = strtobool(os.environ.get(\"AUTOGRADING\", \"false\"))\n",
    "\"\"\n",
    "# create directory for datasets\n",
    "datasets_dir = Path(\"datasets\")\n",
    "datasets_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# create directory for plots\n",
    "outputs_dir = Path(\"outputs\")\n",
    "outputs_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# create directory for state dictionaries of neural network\n",
    "statedicts_dir = Path(\"statedicts\")\n",
    "statedicts_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4f099f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "514e97e4fa143b224ca62b45be78abf9",
     "grade": false,
     "grade_id": "cell-f329788e78cbcb48",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class ThetaDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.x = torch.tensor(dataset[\"th_pix_curr\"], dtype=torch.float32) / 255.0\n",
    "        self.y = torch.tensor(dataset[\"th_curr_ss\"], dtype=torch.float32)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.x[index]\n",
    "        y = self.y[index]\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        num_samples = self.x.shape[0]\n",
    "\n",
    "        return num_samples\n",
    "\n",
    "\n",
    "class TrigDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.x = torch.tensor(dataset[\"th_pix_curr\"], dtype=torch.float32) / 255.0\n",
    "        y_cos = torch.cos(torch.tensor(dataset[\"th_curr_ss\"], dtype=torch.float32))\n",
    "        y_sin = torch.sin(torch.tensor(dataset[\"th_curr_ss\"], dtype=torch.float32))\n",
    "        self.y = torch.cat((y_sin, y_cos), dim=-1)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.x[index]\n",
    "        y = self.y[index]\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        num_samples = self.x.shape[0]\n",
    "\n",
    "        return num_samples\n",
    "\n",
    "\n",
    "class CNNDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.x = (\n",
    "            torch.tensor(\n",
    "                onp.transpose(dataset[\"th_pix_curr\"], (0, 3, 1, 2)), dtype=torch.float32\n",
    "            )\n",
    "            / 255.0\n",
    "        )\n",
    "        y_cos = torch.cos(torch.tensor(dataset[\"th_curr_ss\"], dtype=torch.float32))\n",
    "        y_sin = torch.sin(torch.tensor(dataset[\"th_curr_ss\"], dtype=torch.float32))\n",
    "        self.y = torch.cat((y_sin, y_cos), dim=-1)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.x[index]\n",
    "        y = self.y[index]\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        num_samples = self.x.shape[0]\n",
    "\n",
    "        return num_samples\n",
    "\n",
    "\n",
    "class SNNDataset(Dataset):\n",
    "    def __init__(self, path, num_itr, num_data):\n",
    "        self.path = path\n",
    "        self.num_itr = num_itr\n",
    "        self.num_data = num_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(self.num_itr * self.num_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if index < int(self.num_data * self.num_itr):\n",
    "            spike_path = \"spike\" + str(index) + \".pt\"\n",
    "            label_path = \"target\" + str(index) + \".pt\"\n",
    "            spike_out = torch.load(os.path.join(self.path, spike_path))\n",
    "            label_out = torch.load(os.path.join(self.path, label_path))\n",
    "            return spike_out, label_out\n",
    "        else:\n",
    "            raise IndexError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a9d96c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ea2b15f47033aad1a3884b1ee71ff98",
     "grade": false,
     "grade_id": "cell-3d4e6b84114454e9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def load_training_dataset_dataloader(\n",
    "    _filepath, _rng: random.KeyArray, _val_ratio=0.3, batch_size=64, model_type=\"theta\"\n",
    "):\n",
    "    assert 0.0 <= _val_ratio <= 1.0, \"Validation ratio needs to be in interval [0, 1].\"\n",
    "\n",
    "    _dataset = jnp.load(_filepath)\n",
    "    num_samples = _dataset[\"th_curr_ss\"].shape[0]\n",
    "\n",
    "    indices = jnp.arange(num_samples)\n",
    "    shuffled_indices = random.permutation(_rng, indices)\n",
    "    num_train_samples = int((1 - _val_ratio) * num_samples)\n",
    "    split_config = jnp.array(\n",
    "        [\n",
    "            num_train_samples,\n",
    "        ]\n",
    "    )\n",
    "    train_indices, val_indices = jnp.split(shuffled_indices, split_config)\n",
    "\n",
    "    _train_ds, _val_ds = {}, {}\n",
    "    for key, val in _dataset.items():\n",
    "        _train_ds[key] = val[train_indices]\n",
    "        _val_ds[key] = val[val_indices]\n",
    "\n",
    "    if model_type == \"theta\":\n",
    "        train_data = ThetaDataset(_train_ds)\n",
    "        val_data = ThetaDataset(_val_ds)\n",
    "    elif model_type == \"trig\":\n",
    "        train_data = TrigDataset(_dataset)\n",
    "        val_data = TrigDataset(_val_ds)\n",
    "    elif model_type == \"cnn\":\n",
    "        train_data = CNNDataset(_dataset)\n",
    "        val_data = CNNDataset(_val_ds)\n",
    "\n",
    "    _train_dataloader = torch.utils.data.DataLoader(\n",
    "        train_data, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "    _val_dataloader = torch.utils.data.DataLoader(\n",
    "        val_data, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "\n",
    "    return _train_dataloader, _val_dataloader\n",
    "\n",
    "\n",
    "def load_test_dataset_dataloader(\n",
    "    _filepath, _rng: random.KeyArray, batch_size=64, model_type=\"theta\"\n",
    "):\n",
    "    _dataset = jnp.load(_filepath)\n",
    "    num_samples = _dataset[\"th_curr_ss\"].shape[0]\n",
    "\n",
    "    if model_type == \"theta\":\n",
    "        print(\"Theta Dataset\")\n",
    "        _data = ThetaDataset(_dataset)\n",
    "\n",
    "    elif model_type == \"trig\":\n",
    "        print(\"Trig Dataset\")\n",
    "        _data = TrigDataset(_dataset)\n",
    "    elif model_type == \"cnn\":\n",
    "        print(\"CNN dataset\")\n",
    "        _data = CNNDataset(_dataset)\n",
    "\n",
    "    _dataloader = torch.utils.data.DataLoader(\n",
    "        _data, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "    return _dataloader, _dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a4e89e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b43b36c4af8744d874ed20d4dc23640a",
     "grade": false,
     "grade_id": "cell-406cf2981053231b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(_model, _test_dataset, model=\"theta\", file=\"nothing.pdf\"):\n",
    "    filepath = str(outputs_dir / file)\n",
    "    bin_no = 10\n",
    "    _theta = _test_dataset[\"th_curr_ss\"]\n",
    "    heatmap, xedges, yedges = onp.histogram2d(_theta[:, 0], _theta[:, 1], bins=bin_no)\n",
    "    extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
    "\n",
    "    if model == \"cnn\":\n",
    "        x = onp.transpose(\n",
    "            onp.array(_test_dataset[\"th_pix_curr\"], dtype=onp.float32), (0, 3, 1, 2)\n",
    "        )\n",
    "        y_hat = _model(torch.tensor(x)).detach().numpy()\n",
    "    else:\n",
    "        y_hat = (\n",
    "            _model(\n",
    "                torch.tensor(onp.array(_test_dataset[\"th_pix_curr\"], dtype=onp.float32))\n",
    "            )\n",
    "            .detach()\n",
    "            .numpy()\n",
    "        )  # need to conver back to np array\n",
    "\n",
    "    if model == \"theta\":\n",
    "        y = _test_dataset[\"th_curr_ss\"]\n",
    "    else:\n",
    "        y_cos = onp.cos(_test_dataset[\"th_curr_ss\"])\n",
    "        y_sin = onp.sin(_test_dataset[\"th_curr_ss\"])\n",
    "        y = onp.concatenate((y_cos, y_sin), axis=-1)\n",
    "\n",
    "    error = y_hat - y\n",
    "    error = onp.absolute(error)\n",
    "    ind_th1 = onp.digitize(_test_dataset[\"th_curr_ss\"][:, 0], xedges, right=True)\n",
    "    ind_th2 = onp.digitize(_test_dataset[\"th_curr_ss\"][:, 1], yedges, right=True)\n",
    "\n",
    "    ind_x = []\n",
    "    ind_y = []\n",
    "    for i in range(bin_no):\n",
    "        ind_x.append(onp.where(ind_th1 == (i + 1))[0])\n",
    "        ind_y.append(onp.where(ind_th2 == (i + 1))[0])\n",
    "\n",
    "    avg_bins = onp.zeros((bin_no, bin_no))\n",
    "    for i in range(bin_no):\n",
    "        for j in range(bin_no):\n",
    "            avg_bins[i, j] = (\n",
    "                onp.mean(\n",
    "                    onp.concatenate(\n",
    "                        (error[onp.array(ind_x[i]), 0], error[onp.array(ind_y[j]), 1])\n",
    "                    )\n",
    "                )\n",
    "                / heatmap[i, j]\n",
    "            )\n",
    "\n",
    "    plt.clf()\n",
    "\n",
    "    plt.imshow(avg_bins, extent=extent)\n",
    "    plt.title(\"Heatmap of prediction error\")\n",
    "    plt.colorbar()\n",
    "    plt.savefig(filepath)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def trig_to_theta(trig_data):\n",
    "    trig_len = trig_data.shape[0]\n",
    "    theta = torch.zeros(trig_len, 2)\n",
    "    for i in range(trig_len):\n",
    "        theta[i, 0] = torch.atan2(trig_data[i, 0], trig_data[i, 2])\n",
    "        theta[i, 1] = torch.atan2(trig_data[i, 1], trig_data[i, 3])\n",
    "\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5099e8e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dff9ba4c14f5071a3311380d9c31d49d",
     "grade": false,
     "grade_id": "cell-6bc43ceff8f4cff2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# set seed for jax\n",
    "rng = jax.random.PRNGKey(seed=42)\n",
    "rng, init_rng = jax.random.split(rng)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3321e3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4713f43e52cf23b0b368340cb88e19d4",
     "grade": false,
     "grade_id": "cell-ed9777984ea2045a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task 1.1: Learn to predict angles (7.5p)\n",
    "\n",
    "We are going to create models that try to predict the link angles $\\hat{\\theta}$ given an image of the robot, so $\\theta \\approx \\hat{\\theta} =M(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44751fbe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "56cd7a5915843bdc06aa8ad033bb9a13",
     "grade": false,
     "grade_id": "cell-f7e3713bbf0f4cae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.1 - Prepare data \n",
    "Run the functions below to load the data generated in `task_1a_generate_data.ipynb`, split the training into train/validation and put them in a dataloader. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18479886",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2da45555f320ad4477c7af9bd45b2154",
     "grade": false,
     "grade_id": "cell-404423917ccbeb77",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if not AUTOGRADING:\n",
    "    train_loader_theta, val_loader_theta = load_training_dataset_dataloader(\n",
    "        str(datasets_dir / \"dataset_double_pendulum_train.npz\"),\n",
    "        _rng=init_rng,\n",
    "        model_type=\"theta\",\n",
    "    )\n",
    "    test_loader_theta, test_dataset_theta = load_test_dataset_dataloader(\n",
    "        str(datasets_dir / \"dataset_double_pendulum_test.npz\"),\n",
    "        _rng=init_rng,\n",
    "        model_type=\"theta\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d085abb0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c22658a2d0eccd7d2bde3da4496b076b",
     "grade": false,
     "grade_id": "cell-d9964f8bdfdb040b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.1 - Create the model (1.5p)\n",
    "Here, create a sequaential PyTorch model class called NeuralNetworkTheta()\n",
    "- Start by flattening the input with `torch.flatten()`.\n",
    "- Then, add a fully connected hidden layer `torch.nn.Linear(...)` of 128 units and ReLU activation.\n",
    "- Finally, add a final fully connected linear layer `torch.nn.Linear(...)`without activation. The number of units must match the dimension of our target data, which is 2, as we try to predict the angles $\\theta_1$ and $\\theta_2$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1de9844",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3b686467e1a68c86a6112b99deb0f52f",
     "grade": true,
     "grade_id": "cell-a14f93a12ba0f1a6",
     "locked": false,
     "points": 1.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NN Model with Theta as the output\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" TASK 1.1: CREATE MODEL HERE \"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\"\"\"TASK1.1: END\"\"\"\n",
    "model_theta = NeuralNetworkTheta()\n",
    "\n",
    "total_params_theta = sum(p.numel() for p in model_theta.parameters())\n",
    "print(\"total number of model parameters: \", total_params_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2422298c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "40e03fad60263f41a7c1dd587d72a1d2",
     "grade": false,
     "grade_id": "cell-c87a209ab1dddcd6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.1 - Train the model (2p) \n",
    "\n",
    "Now that the model is defined, we can train it using the training dataset. We have a train-validation split of 0.3 and a batch size of 64 that is shuffled every epoch. Train the model for 50 epochs with the training data `train_loader_theta`. Do this 10 times and record the prediction error of the final model of each of the 10 runs on the test dataset `test_loader_theta` using the function `evaluate_model_test_data_theta`. Don't forget to reinitialize the parameters on each run! **hint:** reduce the number of epochs and lower the number of runs to `1` while getting your model working. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef897c9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab4d80cfbd2fecb6837163c53a6127da",
     "grade": false,
     "grade_id": "cell-1a46c057882f036b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "optimizer = torch.optim.SGD(model_theta.parameters(), lr=1e-3)\n",
    "# We choose the mean square loss as it is a regression problem\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "error_fn = torch.nn.L1Loss()\n",
    "num_epochs = 100\n",
    "\n",
    "\n",
    "def evaluate_model_test_data_theta(_model, _test_loader):\n",
    "    running_loss_test = 0.0\n",
    "    running_error_test = 0.0\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data_test in enumerate(_test_loader):\n",
    "            count += 1\n",
    "            inputs_test, labels_test = data_test\n",
    "            batch = labels_test.shape[0]\n",
    "            est_th = _model(inputs_test)\n",
    "            loss_test = loss_fn(est_th, labels_test)\n",
    "            error_test = error_fn(est_th, labels_test)\n",
    "            running_loss_test += loss_test.item()\n",
    "            running_error_test += error_test.item()\n",
    "    print(\n",
    "        f\"Loss on test data: {running_loss_test / count:.3f}, Average prediction error of model on test data: {running_error_test / count:.3f}\"\n",
    "    )\n",
    "    return running_error_test / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9564fe6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff9ed3b7b89ff636da7d96b562dc8403",
     "grade": true,
     "grade_id": "cell-460ecb4435520c92",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if not AUTOGRADING:\n",
    "    \"\"\"TASK 1.1: TRAIN MODEL HERE\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \"\"\"TASK 1.1: END\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9719a21f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6a100cb89405dba57cce34725835818d",
     "grade": false,
     "grade_id": "cell-4126af15aa526be5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if not AUTOGRADING:\n",
    "    model_theta_scripted = torch.jit.script(model_theta)\n",
    "    model_theta_scripted.save(str(statedicts_dir / \"task_1-1_model_theta.pt\"))\n",
    "    \n",
    "    evaluate_model(\n",
    "        model_theta,\n",
    "        test_dataset_theta,\n",
    "        model=\"theta\",\n",
    "        file=\"task_1-1_model_theta_prediction_error.pdf\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd3ea01",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aa4c2980ebf516a55e0a62a8bfc8d893",
     "grade": false,
     "grade_id": "cell-f481bd08fe4f5192",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.1 - Analyse Model performance (4p)\n",
    "Analyze the prediction accuracy of the model on the test data from heat map of the loss outputted from the `evaluate_model` function. Where does this model have the lowest accuracy? What could be an explanation for the loss of accuracy in those regions? **2p** (Answer in the cell below)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f117ff",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "54660e1d40ec5594a5b7b87d31d75f4b",
     "grade": false,
     "grade_id": "cell-f903416dd8d405dc",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "962e0173",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9c233b9e1058b7cff5574c7eb9b58dc0",
     "grade": false,
     "grade_id": "cell-c2e81017b9edef72",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In general, a separate test dataset is used to evaluate a trained model. Why? **(2p)** (Answer in the cell below)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bd26f9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8c26a04fdc2eaff8735798d2cccdba6a",
     "grade": false,
     "grade_id": "cell-349b357d7c6f715f",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "568cc4a6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2a88dea86fd1937b546e8f22b7b3bb51",
     "grade": false,
     "grade_id": "cell-9767cd0ad15daeab",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task 1.2: Indirectly predict the angle\n",
    "We are going to improve the accuracy by pre-processing the target data. Specifically, we will create a model $M_{trig}$ that learns to predict $\\sin(\\theta)$ and $\\cos(\\theta)$ for both links instead of directly predicting $\\theta$. Then, we can use the trigonometric relation to retrieve an estimate of $\\theta$ for both links.\n",
    "\n",
    "Note: In practice you would use the `atan2` implementation, as the regular arctangent only covers $[-\\frac{1}{2}\\pi, \\frac{1}{2}\\pi]$} $\\theta=\\arctan(\\frac{\\sin(\\theta)}{\\cos(\\theta)})$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edcb3af",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "04e6c4168b305c2fd77bbd5c7634d0ab",
     "grade": false,
     "grade_id": "cell-fed5df7188d95429",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Prepare the data (0p)\n",
    "Run the functions below to load the data generated in `task_1a_generate_data.ipynb`, split the training into train/validation and put them in a dataloader. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41a6eac",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7ca9bfbf9e3a56db4c0d96396fce3fa",
     "grade": false,
     "grade_id": "cell-7cae12728e42a5af",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if not AUTOGRADING:\n",
    "    train_loader_trig, val_loader_trig = load_training_dataset_dataloader(\n",
    "        datasets_dir / \"dataset_double_pendulum_train.npz\",\n",
    "        _rng=init_rng,\n",
    "        model_type=\"trig\",\n",
    "    )\n",
    "    test_loader_trig, test_dataset_trig = load_test_dataset_dataloader(\n",
    "        datasets_dir / \"dataset_double_pendulum_test.npz\",\n",
    "        _rng=init_rng,\n",
    "        model_type=\"trig\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c678bdc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5cfc4df64e3fe110b4a91b531a3636b5",
     "grade": false,
     "grade_id": "cell-3fd3a8ee34be422f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.2 - Create the model (1.5p)\n",
    "\n",
    "Copy the model you created in Task 1.1. Change the number of hidden units of the final layer from 2 to 4. We do so, because we now want to predict two outputs ($\\sin(\\theta)$, $\\cos(\\theta)$) for both link angles, instead of only two outputs, $\\theta_1$ and $\\theta_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7145bd",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9f8aa383eac28da503961ee687a51c60",
     "grade": true,
     "grade_id": "cell-0e4c6601038f04b2",
     "locked": false,
     "points": 1.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" TASK 1.2: CREATE MODEL HERE \"\"\"\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\"\"\"TASK1.2: END\"\"\"\n",
    "\n",
    "model_trig = NeuralNetworkTrig()\n",
    "total_params_trig = sum(p.numel() for p in model_trig.parameters())\n",
    "print(\"Total number of neural network parameters: \", total_params_trig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55b0d23",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3bcf3483f32dc000c46d2510b63a0780",
     "grade": false,
     "grade_id": "cell-8050878591ff79e6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.2 - Train the model (2p)\n",
    "\n",
    "Train the model with the same training parameters defined below as in task 1.1 but using the training data `train_loader_trig`. Do this 10 times and record the prediction error of the final model of each of the 10 runs on the test dataset `test_loader_theta` using the function `evaluate_model_test_data_trig`. Don't forget to reinitialize the parameters on each run! **hint:** reduce the number of epochs and lower the number of runs to `1` while getting your model working. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a3cfdd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f44c8c65a8624324bef1c71d5c92621",
     "grade": false,
     "grade_id": "cell-e5fabcd3354ac38e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "optimizer = torch.optim.SGD(model_trig.parameters(), lr=1e-3)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "error_fn = torch.nn.L1Loss()\n",
    "num_epochs = 100\n",
    "\n",
    "\n",
    "def evaluate_model_test_data_trig(_model, _test_loader):\n",
    "    running_loss_test = 0.0\n",
    "    running_error_test = 0.0\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data_test in enumerate(_test_loader):\n",
    "            count += 1\n",
    "            inputs_test, labels_test = data_test\n",
    "            batch = labels_test.shape[0]\n",
    "            est = _model(inputs_test)\n",
    "            est_th = trig_to_theta(est)\n",
    "            label_th = trig_to_theta(labels_test)\n",
    "            loss_test = loss_fn(est_th, label_th)\n",
    "            error_test = error_fn(est_th, label_th)\n",
    "            running_loss_test += loss_test.item()\n",
    "            running_error_test += error_test.item()\n",
    "    print(\n",
    "        f\"Loss on test data: {running_loss_test / count:.3f}, Average prediction error of model on test data: {running_error_test / count:.3f}\"\n",
    "    )\n",
    "\n",
    "    #     print(f'test loss: {running_loss_train / count_train:.3f}, average test prediction error: {running_error_test / count_train:.3f}')\n",
    "    return running_loss_test / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d0dc0c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "696da14212505114b1a6783a0681554c",
     "grade": true,
     "grade_id": "cell-68238795be7ee278",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if not AUTOGRADING:\n",
    "    \"\"\"TASK 1.2: TRAIN MODEL HERE\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \"\"\"TASK 1.2: END\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a06631",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "faac2afd4a5451bae0d9227b1fbde180",
     "grade": false,
     "grade_id": "cell-537ac57da9947bb3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if not AUTOGRADING:\n",
    "    model_trig_scripted = torch.jit.script(model_trig)\n",
    "    model_trig_scripted.save(str(statedicts_dir / \"task_1-2_model_trig.pt\"))\n",
    "    \n",
    "    evaluate_model(\n",
    "        model_trig,\n",
    "        test_dataset_trig,\n",
    "        model=\"trig\",\n",
    "        file=\"task_1-2_model_trig_prediction_error.pdf\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5f63b1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "55f88a15dfd4da8210da2406d6deef76",
     "grade": false,
     "grade_id": "cell-f481bd08fe4f5191",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.2 - Analyse Model performance (4p)\n",
    "Compare the prediction estimates for $M_{trig}$ with the plot for $M_Œ∏$. Why does indirectly predicting the angle improve the prediction accuracy? **(2p)** (Answer in the cell below)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146c44b2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bbb4a51979b9c16effe3f4355bb62fdd",
     "grade": false,
     "grade_id": "cell-2815ae8a80e8eb78",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2377b1a1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e152dc29dcb3582ed894bbcbe7703f07",
     "grade": false,
     "grade_id": "cell-dc170e69aa93f07f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Why is it not sufficient to predict only sin(Œ∏) and use its inverse Œ∏ = arcsin(sin(Œ∏)) to get an estimate of the angle? **(2p)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af8b427",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fda6f628629541477ea3ea4cdc13af7f",
     "grade": false,
     "grade_id": "cell-dae1ce5f27eb6216",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e3a1cfa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8dbfb868b40c0f2a45d220ec9ff0176d",
     "grade": false,
     "grade_id": "cell-eb4b321fb6188424",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task 1.3: Indirectly predict the angles with a Convolutional Neural Network (10)\n",
    "Instead of using a vanilla fully-connected neural network, we will build a prediction model $M_{cnn}$ that uses a convolutional neural network (CNN). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f81751",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7584d483c176d8e537e9540815b3dd18",
     "grade": false,
     "grade_id": "cell-505fc74a22f4805f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.3 - Prepare the data\n",
    "Run the functions below to load the data generated in `task_1a_generate_data.ipynb`, split the training into train/validation and put them in a dataloader. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7db63cc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "045eb4663c1d4e70c0af94538027d627",
     "grade": false,
     "grade_id": "cell-ba0ddd02786cf10e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if not AUTOGRADING:\n",
    "    train_loader_cnn, val_loader_cnn = load_training_dataset_dataloader(\n",
    "        datasets_dir / \"dataset_double_pendulum_train.npz\",\n",
    "        _rng=init_rng,\n",
    "        model_type=\"cnn\",\n",
    "    )\n",
    "    test_loader_cnn, test_dataset_cnn = load_test_dataset_dataloader(\n",
    "        datasets_dir / \"dataset_double_pendulum_test.npz\",\n",
    "        _rng=init_rng,\n",
    "        model_type=\"cnn\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2dd6c4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "32e1fc9f0bd65b8f42db35a2f99d74c1",
     "grade": false,
     "grade_id": "cell-44f9f0eecd679b24",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.3 - Create the model (2p)\n",
    "Again, create a sequential PyTorch model with `torch.nn.Sequential([...])` and define the following architecture with Convolutional and pooling layers. \n",
    "- Start with a CNN layer `torch.nn.Conv2d(...)` with 32 filters, kernel size of `3x3` and a ReLU activation function.\n",
    "- Add another convolutional layer with 10 filters\n",
    "- Then add a max pooling layer `torch.nn.MaxPool2d(...)` with a pool size of `2x2`.\n",
    "- Flatten the output of the pooling layer\n",
    "- Add a fully connected layer of 30 with a relu activation function.\n",
    "- Finally, add a fully connected layer without activation. Remember, the number of ouput units must match the dimension of the target data, which is 4 as we will predict the trigonometric function again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917b4f02",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7852068c622b938b7e780e1b2cbcd1dc",
     "grade": true,
     "grade_id": "cell-b5d85df96369ff97",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"TASK 1.3: CREATE MODEL HERE\"\"\"\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\"\"\"TASK 1.3: END HERE\"\"\"\n",
    "\n",
    "model_cnn = NeuralNetworkCNN()\n",
    "total_params_cnn = sum(p.numel() for p in model_cnn.parameters())\n",
    "print(\"total number of model parameters: \", total_params_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc0d850",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "01e53f69a2dcaf616ff53e6e42ad13ad",
     "grade": false,
     "grade_id": "cell-ad3641dc5e865e94",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.3 - train the model (2p)\n",
    "\n",
    "Train the model using the same training parameters used in tasks 1.1 and 1.2. \n",
    "\n",
    "Train the model with the same training parameters defined below as in task 1.1 and 1.2 but using the training data `train_loader_cnn`. Do this 10 times and record the prediction error of the final model of each of the 10 runs on the test dataset `test_loader_theta` using the function `evaluate_model_test_data_cnn`. Don't forget to reinitialize the parameters on each run! **hint:** reduce the number of epochs and lower the number of runs to `1` while getting your model working. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b16b565",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6550993cb78720dbec810ecda616ddc7",
     "grade": false,
     "grade_id": "cell-178afa38e9361015",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "optimizer = torch.optim.SGD(model_cnn.parameters(), lr=1e-3)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "error_fn = torch.nn.L1Loss()\n",
    "num_epochs = 100\n",
    "\n",
    "\n",
    "def evaluate_model_test_data_cnn(_model, _test_loader):\n",
    "    \"\"\"\n",
    "    evaluates the model_cnn on the\n",
    "    \"\"\"\n",
    "    running_loss_test = 0.0\n",
    "    running_error_test = 0.0\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data_test in enumerate(_test_loader):\n",
    "            count += 1\n",
    "            inputs_test, labels_test = data_test\n",
    "            #             inputs_test = torch.permute(inputs_test, (0, 3, 1, 2))\n",
    "            batch = labels_test.shape[0]\n",
    "            est = _model(inputs_test)\n",
    "            est_th = trig_to_theta(est)\n",
    "            label_th = trig_to_theta(labels_test)\n",
    "            loss_test = loss_fn(est_th, label_th)\n",
    "            error_test = error_fn(est_th, label_th)\n",
    "            running_loss_test += loss_test.item()\n",
    "            running_error_test += error_test.item()\n",
    "\n",
    "    print(\n",
    "        f\"Loss on test data: {running_loss_test / count:.3f}, Average prediction error of model on test data: {running_error_test / count:.3f}\"\n",
    "    )\n",
    "    return running_error_test / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca36dc7",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7ab216c1249c7a4502aff5a358571257",
     "grade": true,
     "grade_id": "cell-cf838bf5bcf84bdb",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if not AUTOGRADING:\n",
    "    \"\"\"TASK 1.3: TRAIN MODEL HERE\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \"\"\"TASK 1.3: END\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5de0e1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "338fb9bb48e93769373bcafb2cda4cb1",
     "grade": false,
     "grade_id": "cell-4f2f9c81324c39b1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if not AUTOGRADING:\n",
    "    model_cnn_scripted = torch.jit.script(model_cnn)\n",
    "    model_cnn_scripted.save(str(statedicts_dir / \"task_1-3_model_cnn.pt\"))\n",
    "    \n",
    "    evaluate_model(\n",
    "        model_cnn,\n",
    "        test_dataset_cnn,\n",
    "        model=\"cnn\",\n",
    "        file=\"task_1-3_model_cnn_prediction_error.pdf\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547e5145",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8c25c09788fbb8230aa75a0ceaace2a6",
     "grade": false,
     "grade_id": "cell-a5bc36d52b583442",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.3 - Analyse and Compare Model performance \n",
    "Make a comparison of the different models (i.e. M Œ∏, M trig, M cnn) based on the average prediction accuracy\n",
    "on the test dataset and the number of trainable parameters. Which model would you prefer and why? (answer in the cell below)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88887c50",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "059254ea86ccde8458b7cc38ddba71a8",
     "grade": false,
     "grade_id": "cell-e2d3ff8fab5701aa",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "Describe the task here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02731fb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0c145f5b06628fb57436f5c063db3ddc",
     "grade": false,
     "grade_id": "cell-13a942a4eeaa6fcf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "If you change the activation of the last fully connected layer to ReLU, the prediction accuracy completely deteriorates. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c864b2bf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e0a900a0b7319970b0d980bf99cc5e88",
     "grade": false,
     "grade_id": "cell-d18c9ec4e98b87c4",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "Describe the task here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80035d3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7d12b92503515cc3966b23f676f0f149",
     "grade": false,
     "grade_id": "cell-6d6768e940504fa9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task 1.4: Variance across runs (2.5p) \n",
    "In the previous tasks, the prediction accuracy varied across different runs even though the underlying code and dataset remained unchanged.\n",
    "\n",
    "Use the code cell below to set the seed for PyTorch. Train the model for a seed of 0 and then for seed of 1, recording the average prediction accuracy and standard deviation for both. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3206c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)  # set seed to either 0 or 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ca78ff",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "49d443d0d747d8196bfc4b4ff0d634a1",
     "grade": false,
     "grade_id": "cell-1910ebea89f95d4d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Copy the architecture of $M_{cnn}$ to create a new model below. Don't forget to comment on the code to set the seed again when working on the other tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453c25ac",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "07d3a592586350b2cb5ea8a1d31f45e7",
     "grade": true,
     "grade_id": "cell-cc04b732f5935e1b",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" TASK 1.4: CREATE MODEL HERE \"\"\"\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\"\"\"TASK1.4: END\"\"\"\n",
    "model_theta_seed = NeuralNetworkThetaSeed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6aef70d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e8495339b332c4c04d23b078132e7e18",
     "grade": false,
     "grade_id": "cell-ab56a3b7cc55c6c9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Set up a training loop as done for the task 1.3 and run this 10 times while having the seed value as 0 and then run it again for a seed of 1. Use the same datasets as in task 1.3. **(0.5p)**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af73ad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "optimizer = torch.optim.SGD(model_theta_seed.parameters(), lr=1e-3)\n",
    "# We choose the mean square loss as it is a regression problem\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ca4c83",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c9999bb9d7b344750ef96fa475aeb634",
     "grade": true,
     "grade_id": "cell-184b3cffa2fc5614",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if not AUTOGRADING:\n",
    "    losses_seed0 = []\n",
    "    losses_seed1 = []\n",
    "    \"\"\" TASK 1.4: TRAIN MODEL HERE \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \"\"\"TASK 1.4: END\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc62837c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not AUTOGRADING:\n",
    "    model_cnn_scripted = torch.jit.script(model_cnn)\n",
    "    model_cnn_scripted.save(str(statedicts_dir / \"task_1-4_model_cnn.pt\"))\n",
    "    \n",
    "    evaluate_model(\n",
    "        model_cnn,\n",
    "        test_dataset_cnn,\n",
    "        model=\"cnn\",\n",
    "        file=\"task_1-4_model_cnn_prediction_error.pdf\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553da8ec",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a9ff2a2ed28bdb7bb19b1b5bde1f7d5a",
     "grade": false,
     "grade_id": "cell-27be995a7917e630",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- What do you observe? (1p)\n",
    "\n",
    "- What is the benefit of seeding the pseudo-random generator in practice? **(1p)**\n",
    "\n",
    "Write your answers in the cell below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a3bc99",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fcceaa7a9b3691a83394d58d9642d1c4",
     "grade": false,
     "grade_id": "cell-47bf48a2d9c4af1d",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77bf6027",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "27ca38793fa887825118fc29734ef1cc",
     "grade": false,
     "grade_id": "cell-a819e2f73181e95f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### One last thing!\n",
    "A neural network that can predict angles is required for task 2b. Therefore, with the model seeded, you are free to change the training parameters such as learning rate, number of epochs etc. to see how far you can increase the prediction accuracy of link angles. Alternatively, you can just use the standard model trained in 1.4 but be warned the accuracy of your model will affect the performance of you controller in task 2b."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096f6bbc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "08c900766c933fd0e86705af053ce509",
     "grade": false,
     "grade_id": "cell-cec950b501583524",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task 1.5: Spiking neural networks (15p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2de81e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "08ae3a1528be8f96f48c104867175721",
     "grade": false,
     "grade_id": "cell-3d456e0fbb95d0e0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "If our goal is to control the double pendulum, the angular velocity $\\dot{\\theta}$ is generally also required. However, temporal information cannot be extracted from individual images. We are going to utilize the temporal advantage of the spiking neural networks (SNN) to predict the angular velocity of each link. Instead of static individual images, we adopt event-based data as the input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f8128f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a4d5b26ce4148c3dd6acdaa59ed30062",
     "grade": false,
     "grade_id": "cell-013353c1c5418c4c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.5 - Warm Up\n",
    "Use the Jupyter notebook `task_1-5_SNN_warmup.ipynb` to understand the neuron structure of SNNs, construct a LIF neuron model and a simple fully connected SNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b95a69",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "689db5dfe7020b9e10952d935936961a",
     "grade": false,
     "grade_id": "cell-ca0b905a64e10e55",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.5 - Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867a879a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af1c68b5e06dd1d0eaa9687a29efc95c",
     "grade": false,
     "grade_id": "cell-98b1690578b3fdf2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This part has to be same as task_1a_generate_data.ipynb\n",
    "train_th1_range = jnp.arange(-jnp.pi / 6.0, jnp.pi / 6.0, jnp.pi / 30.0)\n",
    "train_th2_range = jnp.arange(-jnp.pi, jnp.pi, jnp.pi / 6.0)\n",
    "test_th1_range = jnp.arange(-jnp.pi / 6.0, jnp.pi / 6.0, jnp.pi / 30.0)\n",
    "test_th2_range = jnp.arange(-jnp.pi, jnp.pi, jnp.pi / 6.0)\n",
    "\n",
    "TRAIN_NUM_DATA = len(train_th1_range) * len(train_th2_range)\n",
    "TEST_NUM_DATA = len(test_th1_range) * len(test_th2_range)\n",
    "NUM_SNN_DATA = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2008b4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b8ba7b8964a14302c608f63e0b552f20",
     "grade": false,
     "grade_id": "cell-7dbf1ba461ec8298",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if not AUTOGRADING:\n",
    "    train_set_snn = SNNDataset(\n",
    "        datasets_dir / \"event_based_data\" / \"train\",\n",
    "        TRAIN_NUM_DATA,\n",
    "        NUM_SNN_DATA,\n",
    "    )\n",
    "    train_loader_snn = DataLoader(train_set_snn, batch_size=16, shuffle=True, drop_last=True)\n",
    "\n",
    "    test_set_snn = SNNDataset(\n",
    "        datasets_dir / \"event_based_data\" / \"test\",\n",
    "        TEST_NUM_DATA,\n",
    "        NUM_SNN_DATA,\n",
    "    )\n",
    "    test_loader_snn = DataLoader(test_set_snn, batch_size=16, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a630360d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0648b8183773e05fb9c2d15bfb3be94e",
     "grade": false,
     "grade_id": "cell-62b53199c8d6ae6b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.5 - Create the model (4p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b79751",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f4f4beb749c031805646773c490e5668",
     "grade": false,
     "grade_id": "cell-25520c2578c97471",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We create a class called `snnModel` extending `nn.Module`. Please fill this class to implement the model of SNNs. We adopt the LIF model for neurons. \\\\\n",
    "\n",
    "* Start with a convolutional layer with 16 as the number of output channels, kernel size of `5x5`.\n",
    "* Then, add a max pooling layer with a pooling size of `4x4`.\n",
    "* Add the second convolutional layer with 16 as output channel size, kernel size of `3x3`.\n",
    "* Add the third convolutional layer with 16 as output channel size, kernel size of `3x3`.\n",
    "* All neurons use LIF model, and obtain the membrane potential in a recurrent way.\n",
    "* Flatten the membrane potential in the last layer and feed it into a non-linear layer with traditional neurons with ReLU as the activation function. The number must match the dimension of our target data which is 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfb92e0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4d92245dd0ca71e6a24aa18edffde7a",
     "grade": true,
     "grade_id": "cell-d96a62b92b1c8df6",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\"\"\"TASK1.5: END\"\"\"\n",
    "\n",
    "model_snn = snnModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fbc824",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ffd0ee3e51ad67893f73f66391591ebb",
     "grade": false,
     "grade_id": "cell-7238196d33aa84de",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.5 - Train the model (3p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036d7b20",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2ba46f079926c8e87810060f8dd29fa7",
     "grade": false,
     "grade_id": "cell-64f390c4e4d9ef2e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Train the SNN model in the same way with other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c630159",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "65f33d5f5980bdd44ea8220ca6ec08e5",
     "grade": false,
     "grade_id": "cell-733f37b346b1f159",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model_snn.parameters(), lr=1e-3)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "num_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f77dbc0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8b82c7bb530ecc3003899cb9af46fd04",
     "grade": true,
     "grade_id": "cell-e365b12765bd52a2",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "onp.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if not AUTOGRADING:\n",
    "\"\"\"TASK 1.5: TRAIN MODEL HERE\"\"\"\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\"\"\"TASK 1.5: END\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56685dd3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a6423bc604006af964380703f4b8453f",
     "grade": false,
     "grade_id": "cell-ff2497b66bbcf9f4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the SNN model with test data\n",
    "if not AUTOGRADING:\n",
    "    with torch.no_grad():\n",
    "        model_snn = model_snn.eval()\n",
    "        print_loss = 0.0\n",
    "        count = 0\n",
    "        for i, (events, targets) in enumerate(test_loader_snn):\n",
    "            output = model_snn(events)\n",
    "            loss = loss_fn(output, targets)\n",
    "            print_loss += loss.item()\n",
    "            count = count + 1\n",
    "\n",
    "        print_loss = print_loss / count\n",
    "        print(f\"The MSE loss of the model on the test dataset is: {print_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8904d5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4ee4b4860a9462b1cb64b2b659d6c119",
     "grade": false,
     "grade_id": "cell-501c8e5f33a32e3f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.5 - Analysis of results (8p)\n",
    "\n",
    "Does your loss decrease step by step? During the training process, is the training speed faster or slower comparing to CNN and why? Please analyse the advantages and disadvantages of SNN. **(8p)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0abd8cc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ef2d0afd82cbd6d2e74a2e1c80465b2a",
     "grade": false,
     "grade_id": "cell-b9f9afb31f989574",
     "locked": true,
     "points": 8,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bd2ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
