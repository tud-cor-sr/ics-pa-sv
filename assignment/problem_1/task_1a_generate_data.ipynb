{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac408b5e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a96d02d6346fa7399cf6da0111ce0937",
     "grade": false,
     "grade_id": "cell-b00828259c8e42e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# RO47019: Intelligent Control Systems Practical Assignment\n",
    "* Period: 2022-2023, Q3\n",
    "* Course homepage: https://brightspace.tudelft.nl/d2l/home/500969\n",
    "* Instructor: Cosimo Della Santina (C.DellaSantina@tudelft.nl)\n",
    "* Teaching assistant: Ruben Martin Rodriguez (R.MartinRodriguez@student.tudelft.nl)\n",
    "* (c) TU Delft, 2023\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or `YOUR ANSWER HERE`. Remove `raise NotImplementedError()` afterwards. Moreover, if you see an empty cell, please DO NOT delete it, instead run that cell as you would run all other cells. Please fill in your name(s) and other required details below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9e220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please fill in your names, student numbers, netID, and emails below.\n",
    "STUDENT_1_NAME = \"\"\n",
    "STUDENT_1_STUDENT_NUMBER = \"\"\n",
    "STUDENT_1_NETID = \"\"\n",
    "STUDENT_1_EMAIL = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba32571",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "042927213b84aa368aa3ea72caa4cb60",
     "grade": true,
     "grade_id": "cell-9f148ec62e0de49c",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Note: this block is a check that you have filled in the above information.\n",
    "# It will throw an AssertionError until all fields are filled\n",
    "assert STUDENT_1_NAME != \"\"\n",
    "assert STUDENT_1_STUDENT_NUMBER != \"\"\n",
    "assert STUDENT_1_NETID != \"\"\n",
    "assert STUDENT_1_EMAIL != \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af317a94",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e76ef40fcc3f08a0484661497162a1a9",
     "grade": false,
     "grade_id": "cell-4ea391677951116c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### General announcements\n",
    "\n",
    "* Do *not* share your solutions, and do *not* copy solutions from others. By submitting your solutions, you claim that you alone are responsible for this code.\n",
    "\n",
    "* Do *not* email questions directly, since we want to provide everybody with the same information and avoid repeating the same answers. Instead, please post your questions regarding this assignment in the correct support forum on Brightspace, this way everybody can benefit from the response. If you do have a particular question that you want to ask directly, please use the scheduled Q&A hours to ask the TA.\n",
    "\n",
    "* There is a strict deadline for each assignment. Students are responsible to ensure that they have uploaded their work in time. So, please double check that your upload succeeded to the Brightspace and avoid any late penalties.\n",
    "\n",
    "* This [Jupyter notebook](https://jupyter.org/) uses `nbgrader` to help us with automated tests. `nbgrader` will make various cells in this notebook \"uneditable\" or \"unremovable\" and gives them a special id in the cell metadata. This way, when we run our checks, the system will check the existence of the cell ids and verify the number of points and which checks must be run. While there are ways that you can edit the metadata and work around the restrictions to delete or modify these special cells, you should not do that since then our nbgrader backend will not be able to parse your notebook and give you points for the assignment. You are free to add additional cells, but if you find a cell that you cannot modify or remove, please know that this is on purpose.\n",
    "\n",
    "* This notebook will have in various places a line that throws a `NotImplementedError` exception. These are locations where the assignment requires you to adapt the code! These lines are just there as a reminder for youthat you have not yet adapted that particular piece of code, especially when you execute all the cells. Once your solution code replaced these lines, it should accordingly *not* throw any exceptions anymore.\n",
    "\n",
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c956945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0948b21",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f5d3a887190ed62931db415da8c3783c",
     "grade": false,
     "grade_id": "cell-80f04a0df76355c7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Task 1.0 - Generate the datasets (0p)\n",
    "\n",
    "**Authors:** Tom√°s Coleman (T.Coleman@tudelft.nl), Chuhan Zhang (C.Zhang-8@tudelft.nl)\n",
    "\n",
    "### Training data for tasks 1.1-1.3\n",
    "\n",
    "In order to train the model, we require data. Therefore, we generate images of the robot at various positions in its state space. \n",
    "At every position chosen in the state space, an RGB image with dimensions 32x32x3, is generated as observation data $x$ together with the corresponding robot state $s=(\\theta, \\dot{\\theta})$, where $\\theta = [\\theta_1, \\theta_2]$ is the link angles of the robot, and $\\dot{\\theta} = [\\dot{\\theta_1}, \\dot{\\theta_2}]$ are the link velocities of the robot. \n",
    "The angle $\\theta_1$ of link 1 and $\\theta_2$ of link 2 are both defined with respect to the right horizontal position (or x-axis), both are wrapped to the $[-\\pi, \\pi]$ domain. \n",
    "$\\dot{\\theta}$ represents the angular velocity. \n",
    "\n",
    "We also generate a test set, which are observations of the robot sampled at every $2^{\\circ}$, of the first link and at every $2^{\\circ}$ of the second link for every sample of the first, giving 32400 (180x180) observations. \n",
    "\n",
    "Run the cells below to generate the data needed for the problems in `task_1b_train_NN.ipynb`.\n",
    "\n",
    "**This notebook is not graded but is required for all tasks of problem 1.**\n",
    "\n",
    "**Please do __not__ include the datasets of Problem 1 in your final submission!** I.e. exclude the `source/problem_1/datasets` folder from your ZIP archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f46e6b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c7346ebd03888faea14f2be6a5a24451",
     "grade": false,
     "grade_id": "cell-b0a5a308ba3ef411",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Reloads the python files outside of this notebook automatically\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import all Python modules\n",
    "from distutils.util import strtobool\n",
    "from functools import partial\n",
    "from IPython.display import display, HTML  # For animations in the notebook\n",
    "from jax.config import config as jax_config\n",
    "\n",
    "jax_config.update(\"jax_platform_name\", \"cpu\")  # set default device to 'cpu'\n",
    "jax_config.update(\"jax_enable_x64\", True)  # double precision\n",
    "from jax import jit, lax, random\n",
    "from jax import numpy as jnp\n",
    "import numpy as onp\n",
    "import cv2\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "from progressbar import progressbar\n",
    "from typing import Dict, Tuple\n",
    "import shutil\n",
    "import torch\n",
    "\n",
    "from jax_double_pendulum.robot_parameters import ROBOT_PARAMS\n",
    "from jax_double_pendulum.robot_simulation import simulate_robot\n",
    "from jax_double_pendulum.kinematics import forward_kinematics\n",
    "from jax_double_pendulum.utils import normalize_link_angles\n",
    "from utils import *\n",
    "\n",
    "\n",
    "# define boolean to check if the notebook is run for the purposes of autograding\n",
    "AUTOGRADING = strtobool(os.environ.get(\"AUTOGRADING\", \"false\"))\n",
    "\n",
    "# folder to save the dataset to\n",
    "datasets_folder = Path(\"datasets\")\n",
    "datasets_folder.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# create directory for plots\n",
    "outputs_dir = Path(\"outputs\")\n",
    "outputs_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117b6ae4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "27b8a281a893fe7c09daf3a0671c59a3",
     "grade": false,
     "grade_id": "cell-81c5e7055cab8f7c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Generating dataset of state images \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76f4bbe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8f66e39aae3e9417147a7dde0e6b00b3",
     "grade": false,
     "grade_id": "cell-cc1df24ab91e26fe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def save_test_data_to_dataset(\n",
    "    _dataset: Dict[str, jnp.ndarray],\n",
    "    initial_conditions: jnp.array,\n",
    ") -> Dict[str, jnp.ndarray]:\n",
    "    num_ic = initial_conditions.shape[0]\n",
    "    _dataset[\"th_curr_ss\"] = _dataset[\"th_curr_ss\"].at[:].set(initial_conditions)\n",
    "\n",
    "    def _for_loop_cart_fun(idx, _dataset: Dict):\n",
    "        _x_eb, _x = forward_kinematics(ROBOT_PARAMS, _dataset[\"th_curr_ss\"][idx])\n",
    "        _dataset[\"x_eb_ts\"] = _dataset[\"x_eb_ts\"].at[idx].set(_x_eb)\n",
    "        _dataset[\"x_ts\"] = _dataset[\"x_ts\"].at[idx].set(_x)\n",
    "        return _dataset\n",
    "\n",
    "    _dataset = lax.fori_loop(\n",
    "        lower=0, upper=num_ic, body_fun=_for_loop_cart_fun, init_val=_dataset\n",
    "    )\n",
    "\n",
    "    return _dataset\n",
    "\n",
    "\n",
    "def save_training_data_to_dataset(\n",
    "    _dataset: Dict[str, jnp.ndarray], sim_idx: int, sim_ts: Dict[str, jnp.array]\n",
    ") -> Dict[str, jnp.ndarray]:\n",
    "    sim_length = sim_ts[\"th_ts\"].shape[0]\n",
    "\n",
    "    _dataset[\"th_curr_ss\"] = (\n",
    "        _dataset[\"th_curr_ss\"]\n",
    "        .at[(sim_idx * sim_length) : ((sim_idx + 1) * sim_length)]\n",
    "        .set(normalize_link_angles(sim_ts[\"th_ts\"]))\n",
    "    )\n",
    "\n",
    "    _dataset[\"x_eb_ts\"] = (\n",
    "        _dataset[\"x_eb_ts\"]\n",
    "        .at[(sim_idx * sim_length) : ((sim_idx + 1) * sim_length)]\n",
    "        .set(sim_ts[\"x_eb_ts\"])\n",
    "    )\n",
    "\n",
    "    _dataset[\"x_ts\"] = (\n",
    "        _dataset[\"x_ts\"]\n",
    "        .at[(sim_idx * sim_length) : ((sim_idx + 1) * sim_length)]\n",
    "        .set(sim_ts[\"x_ts\"])\n",
    "    )\n",
    "\n",
    "    return _dataset\n",
    "\n",
    "\n",
    "@jit\n",
    "def sample_system_evolution(\n",
    "    _sim_idx: int, _rng: random.KeyArray, _t_ts: jnp.array\n",
    ") -> Tuple[Dict[str, jnp.ndarray], random.KeyArray]:\n",
    "    \"\"\"\n",
    "    Samples a system evolution from the robot simulation.\n",
    "    Args:\n",
    "        _sim_idx: Index of the simulation.\n",
    "        _rng: JAX random number generator.\n",
    "    Returns:\n",
    "        _sim_ts: Dictionary containing the time series of system states.\n",
    "        _rng: JAX random number generator (updated).\n",
    "    \"\"\"\n",
    "    _rng, subkey1, subkey2 = random.split(_rng, 3)\n",
    "\n",
    "    max_th_d = 1 * jnp.pi\n",
    "\n",
    "    _th_0 = random.uniform(\n",
    "        key=subkey1, minval=-jnp.pi, maxval=jnp.pi, shape=(2,)\n",
    "    )  # [rad]\n",
    "    _th_d_0 = random.uniform(\n",
    "        key=subkey2, minval=-max_th_d, maxval=max_th_d, shape=(2,)\n",
    "    )  # [rad/s]\n",
    "\n",
    "    _sim_ts = simulate_robot(\n",
    "        rp=ROBOT_PARAMS,\n",
    "        t_ts=_t_ts,\n",
    "        th_0=_th_0,\n",
    "        th_d_0=_th_d_0,\n",
    "    )\n",
    "\n",
    "    return _sim_ts, _rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb5bbb0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aaa05562be52bbb3a7080b245cb51fe1",
     "grade": false,
     "grade_id": "cell-9e08a807e942bfe7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def save_image_data_to_dataset(\n",
    "    _dataset: Dict[str, jnp.ndarray], ROBOT_PARAMS: Dict[str, jnp.ndarray]\n",
    ") -> Dict[str, jnp.ndarray]:\n",
    "    _dataset = draw_robot(_dataset, ROBOT_PARAMS)\n",
    "\n",
    "    return _dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea38041",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b3a9fdc7e18a15b4d5364f832a8c43a",
     "grade": false,
     "grade_id": "cell-5ae302690b9a1219",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def save_image_data_to_dataset_snn(\n",
    "    _dataset: Dict[str, jnp.ndarray], ROBOT_PARAMS: Dict[str, jnp.ndarray]\n",
    ") -> Dict[str, jnp.ndarray]:\n",
    "    _dataset = draw_robot_snn(_dataset, ROBOT_PARAMS)\n",
    "\n",
    "    return _dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f760c34d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fd02ccbcbdd0a86c33d037141ea1282d",
     "grade": false,
     "grade_id": "cell-6517c41248cb3d25",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# initialize random number generator\n",
    "key = random.PRNGKey(seed=42)\n",
    "\n",
    "# simulation parameters\n",
    "num_samples_train = 20000\n",
    "num_ic_train = 20000\n",
    "sim_dt = 1e-2\n",
    "img_size = 32\n",
    "sim_duration_train = (sim_dt * num_samples_train) / num_ic_train\n",
    "print(\"Duration of a single simulation: \", sim_duration_train)\n",
    "\n",
    "# define time steps\n",
    "t_ts = sim_dt * jnp.arange(int(sim_duration_train / sim_dt))\n",
    "\n",
    "# Generate test data: 90 x 90\n",
    "th1_range = jnp.arange(-jnp.pi, jnp.pi, jnp.pi / 90.0)\n",
    "th2_range = jnp.arange(-jnp.pi, jnp.pi, jnp.pi / 90.0)\n",
    "\n",
    "initial_conditions = jnp.array(jnp.meshgrid(th1_range, th2_range)).T.reshape(-1, 2)\n",
    "\n",
    "num_samples_test = len(th1_range) * len(th2_range)\n",
    "\n",
    "\n",
    "training_dataset = {\n",
    "    \"th_curr_ss\": jnp.zeros((num_samples_train, 2)),\n",
    "    \"x_eb_ts\": jnp.zeros((num_samples_train, 2)),\n",
    "    \"x_ts\": jnp.zeros((num_samples_train, 2)),\n",
    "    \"th_pix_curr\": jnp.zeros(\n",
    "        (num_samples_train, img_size, img_size, 3), dtype=jnp.uint8\n",
    "    ),\n",
    "}\n",
    "\n",
    "test_dataset = {\n",
    "    \"th_curr_ss\": jnp.zeros((num_samples_test, 2)),\n",
    "    \"x_eb_ts\": jnp.zeros((num_samples_test, 2)),\n",
    "    \"x_ts\": jnp.zeros((num_samples_test, 2)),\n",
    "    \"th_pix_curr\": jnp.zeros(\n",
    "        (num_samples_test, img_size, img_size, 3), dtype=jnp.uint8\n",
    "    ),\n",
    "}\n",
    "\n",
    "print(\"Sampling system evolutions for the trainings set ...\")\n",
    "for sim_idx in progressbar(range(num_ic_train)):\n",
    "    sim_ts, key = sample_system_evolution(sim_idx, key, t_ts)\n",
    "\n",
    "    training_dataset = save_training_data_to_dataset(training_dataset, sim_idx, sim_ts)\n",
    "\n",
    "test_dataset = save_test_data_to_dataset(test_dataset, initial_conditions)\n",
    "\n",
    "print(\"Rendering images of the robot for the training set ...\")\n",
    "training_dataset = save_image_data_to_dataset(training_dataset, ROBOT_PARAMS)\n",
    "\n",
    "print(\"Rendering images of the robot for the test set ...\")\n",
    "test_dataset = save_image_data_to_dataset(test_dataset, ROBOT_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913fb11b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb6bc0ce4d44e2e10b5b6c1b1c9a5f2f",
     "grade": false,
     "grade_id": "cell-1b212ae7fb3bdbe1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "jnp.savez(\n",
    "    file=str(datasets_folder / \"dataset_double_pendulum_train.npz\"), **training_dataset\n",
    ")\n",
    "jnp.savez(file=str(datasets_folder / \"dataset_double_pendulum_test.npz\"), **test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803a9bcd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "35373d998fa3d20bb26d3ae7344ef3fe",
     "grade": false,
     "grade_id": "cell-a80c2b186ed2b196",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def data_distribution(_theta):\n",
    "    bin_no = 100\n",
    "    heatmap, xedges, yedges = onp.histogram2d(_theta[:, 0], _theta[:, 1], bins=bin_no)\n",
    "    extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
    "    plt.clf()\n",
    "    plt.imshow(heatmap.T, extent=extent)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "data_distribution(training_dataset[\"th_curr_ss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4662bbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a random image from the training dataset\n",
    "\n",
    "index = onp.random.randint(0, num_samples_train)\n",
    "print(\"index\", index)\n",
    "print(\"theta: \", training_dataset[\"th_curr_ss\"][index])\n",
    "plt.imshow(training_dataset[\"th_pix_curr\"][index, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c80c15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a random image from the training dataset\n",
    "\n",
    "index = onp.random.randint(0, 180 * 180)\n",
    "print(\"index\", index)\n",
    "print(\"theta: \", test_dataset[\"th_curr_ss\"][index])\n",
    "plt.imshow(test_dataset[\"th_pix_curr\"][index, :, :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1456ecdc",
   "metadata": {},
   "source": [
    "## Generating simulated event-based dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560df61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def save_sim_data_to_dataset_snn(\n",
    "    _dataset: Dict[str, jnp.ndarray],\n",
    "    _sim_idx: int,\n",
    "    _sim_ts: Dict[str, jnp.ndarray],\n",
    ") -> Dict[str, jnp.ndarray]:\n",
    "    _dataset[\"th_curr_ss\"] = (\n",
    "        _dataset[\"th_curr_ss\"].at[_sim_idx].set(_sim_ts[\"th_ts\"][0])\n",
    "    )\n",
    "\n",
    "    _dataset[\"th_d_curr_ss\"] = (\n",
    "        _dataset[\"th_d_curr_ss\"].at[_sim_idx].set(_sim_ts[\"th_d_ts\"][0])\n",
    "    )\n",
    "\n",
    "    _dataset[\"x_eb_ts\"] = _dataset[\"x_eb_ts\"].at[_sim_idx].set(_sim_ts[\"x_eb_ts\"][0])\n",
    "    _dataset[\"x_ts\"] = _dataset[\"x_ts\"].at[_sim_idx].set(_sim_ts[\"x_ts\"][0])\n",
    "\n",
    "    # Windowed data for SNN\n",
    "    _dataset[\"th_window_snn\"] = (\n",
    "        _dataset[\"th_window_snn\"].at[_sim_idx, :, :].set(_sim_ts[\"th_ts\"])\n",
    "    )\n",
    "\n",
    "    _dataset[\"th_d_window_snn\"] = (\n",
    "        _dataset[\"th_d_window_snn\"].at[_sim_idx, :, :].set(_sim_ts[\"th_d_ts\"])\n",
    "    )\n",
    "\n",
    "    _dataset[\"x_eb_ts_window_snn\"] = (\n",
    "        _dataset[\"x_eb_ts_window_snn\"].at[_sim_idx, :, :].set(_sim_ts[\"x_eb_ts\"])\n",
    "    )\n",
    "    _dataset[\"x_ts_window_snn\"] = (\n",
    "        _dataset[\"x_ts_window_snn\"].at[_sim_idx, :, :].set(_sim_ts[\"x_ts\"])\n",
    "    )\n",
    "    return _dataset\n",
    "\n",
    "\n",
    "@jit\n",
    "def generate_data_point(ic, _rng, _t_ts):\n",
    "    \"\"\"\n",
    "    Generates a data point for the state of the robot from a given angle.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # for ic_idx in range(initial_conditions, 1):\n",
    "\n",
    "    _rng, subkey1, subkey2 = random.split(_rng, 3)\n",
    "\n",
    "    max_th_d = 1 * jnp.pi\n",
    "\n",
    "    _th_d_0 = onp.array([max_th_d, max_th_d])\n",
    "    _sim_ts = simulate_robot(rp=ROBOT_PARAMS, t_ts=_t_ts, th_0=ic, th_d_0=_th_d_0)\n",
    "    return _sim_ts, _rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc10b574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize random number generator\n",
    "key = random.PRNGKey(seed=42)\n",
    "\n",
    "# simulation parameters\n",
    "sim_duration = 5.05\n",
    "sim_dt = 5e-3\n",
    "img_size = 32\n",
    "# Since the big O is not good compared to the size of dataset,\n",
    "# Run this multiple times for different sections of the first link,\n",
    "# then bring them together in the training file.\n",
    "train_th1_range = jnp.arange(-jnp.pi / 6.0, jnp.pi / 6.0, jnp.pi / 30.0)\n",
    "train_th2_range = jnp.arange(-jnp.pi, jnp.pi, jnp.pi / 6.0)\n",
    "test_th1_range = jnp.arange(-jnp.pi / 6.0, jnp.pi / 6.0, jnp.pi / 30.0)\n",
    "test_th2_range = jnp.arange(-jnp.pi, jnp.pi, jnp.pi / 6.0)\n",
    "\n",
    "\n",
    "# initial_conditions = jnp.array([th_range, th_range])\n",
    "train_initial_conditions = jnp.array(\n",
    "    jnp.meshgrid(train_th1_range, train_th2_range)\n",
    ").T.reshape(-1, 2)\n",
    "test_initial_conditions = jnp.array(\n",
    "    jnp.meshgrid(test_th1_range, test_th2_range)\n",
    ").T.reshape(-1, 2)\n",
    "\n",
    "# define time steps\n",
    "t_ts = sim_dt * jnp.arange(int(sim_duration / sim_dt))\n",
    "\n",
    "# set global variables\n",
    "TRAIN_NUM_DATA = len(train_th1_range) * len(train_th2_range)\n",
    "TEST_NUM_DATA = len(test_th1_range) * len(test_th2_range)\n",
    "NUM_SNN_DATA = 5\n",
    "\n",
    "\n",
    "trainset = {\n",
    "    \"dt_ss\": sim_dt * jnp.ones(TRAIN_NUM_DATA, dtype=jnp.float32),\n",
    "    \"th_curr_ss\": jnp.zeros((TRAIN_NUM_DATA, 2), dtype=jnp.float32),\n",
    "    \"th_window_snn\": jnp.zeros((TRAIN_NUM_DATA, 1010, 2), dtype=jnp.float32),\n",
    "    \"th_d_curr_ss\": jnp.zeros((TRAIN_NUM_DATA, 2), dtype=jnp.float32),\n",
    "    \"th_d_window_snn\": jnp.zeros((TRAIN_NUM_DATA, 1010, 2), dtype=jnp.float32),\n",
    "    \"x_eb_ts\": jnp.zeros((TRAIN_NUM_DATA, 2), dtype=jnp.float32),\n",
    "    \"x_ts\": jnp.zeros((TRAIN_NUM_DATA, 2), dtype=jnp.float32),\n",
    "    \"x_eb_ts_window_snn\": jnp.zeros((TRAIN_NUM_DATA, 1010, 2), dtype=jnp.float32),\n",
    "    \"x_ts_window_snn\": jnp.zeros((TRAIN_NUM_DATA, 1010, 2), dtype=jnp.float32),\n",
    "    \"th_pix_curr\": jnp.zeros(\n",
    "        (TRAIN_NUM_DATA, img_size, img_size, 3), dtype=jnp.float32\n",
    "    ),\n",
    "    \"th_pix_window_snn\": jnp.zeros(\n",
    "        (TRAIN_NUM_DATA, 1010, img_size, img_size, 3), dtype=jnp.float32\n",
    "    ),\n",
    "}\n",
    "testset = {\n",
    "    \"dt_ss\": sim_dt * jnp.ones(TEST_NUM_DATA, dtype=jnp.float32),\n",
    "    \"th_curr_ss\": jnp.zeros((TEST_NUM_DATA, 2), dtype=jnp.float32),\n",
    "    \"th_window_snn\": jnp.zeros((TEST_NUM_DATA, 1010, 2), dtype=jnp.float32),\n",
    "    \"th_d_curr_ss\": jnp.zeros((TEST_NUM_DATA, 2), dtype=jnp.float32),\n",
    "    \"th_d_window_snn\": jnp.zeros((TEST_NUM_DATA, 1010, 2), dtype=jnp.float32),\n",
    "    \"x_eb_ts\": jnp.zeros((TEST_NUM_DATA, 2), dtype=jnp.float32),\n",
    "    \"x_ts\": jnp.zeros((TEST_NUM_DATA, 2), dtype=jnp.float32),\n",
    "    \"x_eb_ts_window_snn\": jnp.zeros((TEST_NUM_DATA, 1010, 2), dtype=jnp.float32),\n",
    "    \"x_ts_window_snn\": jnp.zeros((TEST_NUM_DATA, 1010, 2), dtype=jnp.float32),\n",
    "    \"th_pix_curr\": jnp.zeros((TEST_NUM_DATA, img_size, img_size, 3), dtype=jnp.float32),\n",
    "    \"th_pix_window_snn\": jnp.zeros(\n",
    "        (TEST_NUM_DATA, 1010, img_size, img_size, 3), dtype=jnp.float32\n",
    "    ),\n",
    "}\n",
    "\n",
    "print(\"Generating simulation data for the SNN training set ...\")\n",
    "for sim_idx in progressbar(range(TRAIN_NUM_DATA)):\n",
    "    sim_ts, key = generate_data_point(train_initial_conditions[sim_idx], key, t_ts)\n",
    "    trainset = save_sim_data_to_dataset_snn(trainset, sim_idx, sim_ts)\n",
    "    \n",
    "print(\"Generating simulation data for the SNN test set ...\")\n",
    "for sim_idx in progressbar(range(TEST_NUM_DATA)):\n",
    "    sim_ts, key = generate_data_point(test_initial_conditions[sim_idx], key, t_ts)\n",
    "    testset = save_sim_data_to_dataset_snn(testset, sim_idx, sim_ts)\n",
    "\n",
    "print(\"Rendering images of the robot for the SNN training set ...\")\n",
    "trainset = save_image_data_to_dataset_snn(trainset, ROBOT_PARAMS)\n",
    "print(\"Rendering images of the robot for the SNN test set ...\")\n",
    "testset = save_image_data_to_dataset_snn(testset, ROBOT_PARAMS)\n",
    "\n",
    "print(f\"Start save the images to the file:\")\n",
    "jnp.savez(\n",
    "    file=str(datasets_folder / \"dataset_double_pendulum_snn_train.npz\"), **trainset\n",
    ")\n",
    "jnp.savez(file=str(datasets_folder / \"dataset_double_pendulum_snn_test.npz\"), **testset)\n",
    "print(f\"save successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8584a8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a799a8e11b72cf694964cda1f283826e",
     "grade": false,
     "grade_id": "cell-153af02d145a72de",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Transfer RGB image data into simulated event-based data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149fa0e0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d687fb52710a959b117e7bf2c9414486",
     "grade": false,
     "grade_id": "cell-7484fca329336081",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def trainset_transform_to_snn(datasets_folder):\n",
    "    velocity, observation = read_data(\n",
    "        str(datasets_folder / \"dataset_double_pendulum_snn_train.npz\")\n",
    "    )\n",
    "\n",
    "    snn_data = generate_snn_data(observation, TRAIN_NUM_DATA, NUM_SNN_DATA)\n",
    "    train_set_dir = datasets_folder / \"event_based_data\" / \"train\"\n",
    "    if os.path.exists(train_set_dir):\n",
    "        if os.path.getsize(train_set_dir) == 0:\n",
    "            os.removedirs(train_set_dir)\n",
    "        else:\n",
    "            shutil.rmtree(train_set_dir)\n",
    "    os.makedirs(train_set_dir)\n",
    "\n",
    "    divide_and_save_data(snn_data, velocity, TRAIN_NUM_DATA, NUM_SNN_DATA, dir)\n",
    "\n",
    "\n",
    "def testset_transform_to_snn(datasets_folder):\n",
    "    velocity, observation = read_data(\n",
    "        str(datasets_folder / \"dataset_double_pendulum_snn_test.npz\")\n",
    "    )\n",
    "\n",
    "    snn_data = generate_snn_data(observation, TEST_NUM_DATA, NUM_SNN_DATA)\n",
    "    test_set_dir = datasets_folder / \"event_based_data\" / \"test\"\n",
    "    if os.path.exists(test_set_dir):\n",
    "        if os.path.getsize(test_set_dir) == 0:\n",
    "            os.removedirs(test_set_dir)\n",
    "        else:\n",
    "            shutil.rmtree(test_set_dir)\n",
    "    os.makedirs(test_set_dir)\n",
    "\n",
    "    divide_and_save_data(snn_data, velocity, TEST_NUM_DATA, NUM_SNN_DATA, dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a140d314",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6bb0b2a8aaa2ca03a8396311b04737c1",
     "grade": false,
     "grade_id": "cell-33da2085f09fb401",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Transform RGB sequential images into event-based data\")\n",
    "trainset_transform_to_snn(datasets_folder)\n",
    "testset_transform_to_snn(datasets_folder)\n",
    "print(f\"Finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b82bfe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9d5e64eda7847079aa1a671b8039777d",
     "grade": false,
     "grade_id": "cell-9b995596da8c8a6a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Show examples of SNN data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9063a181",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eea1fc4aa3274184f71aab63aec2dfff",
     "grade": false,
     "grade_id": "cell-a1e1686afbe08372",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Print a random SNN data from the training dataset\n",
    "\n",
    "index = onp.random.randint(0, TRAIN_NUM_DATA * NUM_SNN_DATA)\n",
    "print(index)\n",
    "spike = torch.load(\n",
    "    str(datasets_folder / \"event_based_data\" / \"train\" / f\"spike{int(index)}.pt\")\n",
    ")\n",
    "snn_animation(spike, str(outputs_dir / \"snn_train_example.gif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab66178",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4753a68a495fdd4500c5e4973a738e2d",
     "grade": false,
     "grade_id": "cell-0d435bba5acb4302",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Print a random SNN data from the test dataset\n",
    "\n",
    "index = onp.random.randint(0, TEST_NUM_DATA * NUM_SNN_DATA)\n",
    "print(index)\n",
    "spike = torch.load(\n",
    "    str(datasets_folder / \"event_based_data\" / \"test\" / f\"spike{int(index)}.pt\")\n",
    ")\n",
    "snn_animation(spike, str(outputs_dir / \"snn_test_example.gif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bc7a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
